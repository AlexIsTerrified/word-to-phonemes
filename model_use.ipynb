{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "\n",
    "model = load_model('phoneme_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.get_layer(index=4)\n",
    "char_input = model.get_layer(index=0)\n",
    "ph_input = model.get_layer(index=1)\n",
    "embedding_layer = model.get_layer(index=3)\n",
    "decoder_lstm = model.get_layer(index=5)\n",
    "softmax_dense = model.get_layer(index=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_y, state_h, state_c = encoder.output\n",
    "char_input = char_input.output\n",
    "ph_input = ph_input.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('char_tokenizer.json') as f:\n",
    "    data = json.load(f)\n",
    "    char_tokenizer = tokenizer_from_json(data)\n",
    "with open('phone_tokenizer.json') as f:\n",
    "    data = json.load(f)\n",
    "    phone_tokenizer = tokenizer_from_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(char_input, [state_h, state_c])\n",
    "\n",
    "#Decoder\n",
    "decoder_input_h = Input(shape=(256,))\n",
    "decoder_input_c = Input(shape=(256,))\n",
    "x = embedding_layer(ph_input)\n",
    "x, decoder_output_h, decoder_output_c = decoder_lstm(x, initial_state=[decoder_input_h, decoder_input_c])\n",
    "x = softmax_dense(x)\n",
    "decoder = Model([ph_input] + [decoder_input_h, decoder_input_c], \n",
    "                                [x] + [decoder_output_h, decoder_output_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pronunciation(ch_input):\n",
    "    input_seq = char_tokenizer.texts_to_sequences([ch_input])\n",
    "\n",
    "    next_h, next_c = encoder.predict(input_seq)\n",
    "\n",
    "    curr_token = np.zeros((1,1))\n",
    "    curr_token[0] = phone_tokenizer.word_index['startseq']\n",
    "\n",
    "    pred_sentence = ''\n",
    "\n",
    "    for i in range(21):\n",
    "        output, next_h, next_c = decoder.predict([curr_token] + [next_h, next_c],verbose=0)\n",
    "        next_token = np.argmax(output[0, 0, :])\n",
    "        next_word = phone_tokenizer.index_word[next_token]\n",
    "        if next_word == 'endseq':\n",
    "            break\n",
    "        else:\n",
    "            pred_sentence += ' ' + next_word\n",
    "            curr_token[0] = next_token\n",
    "\n",
    "    return pred_sentence.replace(\"startseq\",\"\").replace(\"endseq\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
